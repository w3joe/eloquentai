
# VoiceMind — Voice-First Language Learning App

## Phase 1: Foundation & Design System

Set up the app's visual identity with the dark navy theme (`#0F0F1A` background, `#6C63FF` accent, `#F0F0F5` text), Plus Jakarta Sans font, and smooth screen transitions. Configure Tailwind with custom color tokens and create reusable animated components (pulsing orb, gradient-bordered cards, circular progress rings).

## Phase 2: Onboarding Flow (Screen 1 → Screen 2)

**Screen 1 — "Tell us about yourself"**
- Full-screen centered card with language selectors (with flag emojis), a large free-text bio textarea, and freeform context tag chips
- CTA: "Build My Profile →" with a loading transition ("Learning about you...")

**Screen 2 — Profile Summary**
- Display extracted profile sections (profession, interests, conversation topics, target language & level) in a clean card with user initials avatar
- Inline editing on each section
- CTA: "Start Practicing →" navigates to home

Profile data is saved to Supabase `profiles` table with auth, so it persists across sessions.

## Phase 3: Supabase Backend Setup

- **Auth**: Email-based signup/login
- **Database tables**: `profiles` (bio, native language, target language, context tags, extracted interests), `sessions` (scenario, transcript, feedback, fluency score, date), `vocabulary` (saved words from feedback)
- **Edge function**: `elevenlabs-conversation-token` — securely generates a conversation token using the ElevenLabs API key stored as a Supabase secret
- **Edge function**: `generate-feedback` — sends conversation transcript to Claude API and returns structured corrections, vocabulary, and summary

## Phase 4: Home / Scenario Selection (Screen 3)

- Personalized greeting based on profile name and target language
- "Suggested for you" section with 3 scenario cards generated from mock data (AI generation can be wired later). Each card shows title, description, difficulty badge, duration, and context icon
- "Custom scenario" text input with Go button
- Bottom navigation: Home · History · Profile

## Phase 5: Pre-Conversation Briefing (Screen 4)

- Full-screen scene description with character card (name, role, personality, voice label)
- Language and difficulty badge
- Collapsible tips section
- Large pulsing mic button CTA: "Start Conversation"

## Phase 6: Voice Conversation — Core Experience (Screen 5)

- Animated orb/waveform center stage, reacting to conversation state
  - Violet pulse when agent speaks, white pulse when user speaks, breathing animation when processing, grey pulse when connecting, red flash on error
- Character name and scene label at top
- Small "End Conversation" button at bottom
- Toggle-able live transcript sliding up from bottom
- Integrates ElevenLabs `useConversation` hook with real WebRTC connection via the token edge function
- Friendly mic permission overlay if access is denied

## Phase 7: Post-Conversation Feedback (Screen 6)

- Circular progress ring showing fluency score (0–100)
- Three tabs:
  - **Corrections**: Error cards with "what you said" (coral) vs correction (green) + explanation
  - **Vocabulary**: Notable words/phrases with translation, example sentence, and "+ Save" button (saves to Supabase vocabulary table)
  - **Summary**: Performance paragraph, "focus for next session" tip, session metadata
- CTAs: "Practice Again" · "Back to Home"
- Feedback generated by calling the `generate-feedback` edge function (uses mock/structured data initially, real Claude integration via edge function)

## Phase 8: ElevenLabs Connection

Connect the ElevenLabs connector to the project so the API key is available as an environment variable for the conversation token edge function. The voice conversation screen will use real two-way voice via WebRTC.
